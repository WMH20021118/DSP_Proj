{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b70c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bad385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "races_df = pd.read_csv('races.csv')\n",
    "runs_df = pd.read_csv('runs.csv')\n",
    "\n",
    "# 生成骑师的总比赛场次和胜利场次列\n",
    "runs_df['total_races'] = runs_df.groupby('jockey_id').cumcount() + 1\n",
    "runs_df['total_wins'] = runs_df.groupby('jockey_id')['won'].cumsum()\n",
    "\n",
    "# 合并数据\n",
    "merged_df = pd.merge(runs_df, races_df, on='race_id')\n",
    "\n",
    "# 筛选需要的特征列\n",
    "features = ['race_id', 'venue', 'config', 'surface', 'distance', 'horse_age', 'horse_country', \n",
    "            'horse_type', 'horse_rating', 'declared_weight', 'actual_weight', 'total_races', 'total_wins']\n",
    "merged_df = merged_df[features + ['result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbd0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出每个 race_id 对应的最大马匹数\n",
    "max_horses_per_race = 14\n",
    "\n",
    "# 获取所有的 race_id\n",
    "all_race_ids = merged_df['race_id'].unique()\n",
    "\n",
    "# 创建一个新的 DataFrame 用于存储补全后的数据\n",
    "complete_df = pd.DataFrame()\n",
    "\n",
    "for race_id in all_race_ids:\n",
    "    race_data = merged_df[merged_df['race_id'] == race_id]\n",
    "    num_horses = len(race_data)\n",
    "    \n",
    "    if num_horses < max_horses_per_race:\n",
    "        # 计算需要补全的马匹数\n",
    "        num_to_add = max_horses_per_race - num_horses\n",
    "        \n",
    "        # 生成补全数据\n",
    "        to_add = pd.DataFrame(0, index=np.arange(num_to_add), columns=race_data.columns)\n",
    "        to_add['race_id'] = race_id\n",
    "        \n",
    "        # 合并补全数据\n",
    "        race_data = pd.concat([race_data, to_add], ignore_index=True)\n",
    "    \n",
    "    # 将补全后的数据添加到 complete_df 中\n",
    "    complete_df = pd.concat([complete_df, race_data], ignore_index=True)\n",
    "\n",
    "# 处理缺失值（示例：用均值填充）\n",
    "complete_df.fillna(complete_df.mean(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729bbba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保类别变量为字符串类型\n",
    "categorical_cols = ['venue', 'config', 'surface', 'horse_country', 'horse_type']\n",
    "for col in categorical_cols:\n",
    "    complete_df[col] = complete_df[col].astype(str)\n",
    "\n",
    "# 保存类别变量编码器\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(complete_df[categorical_cols])\n",
    "\n",
    "# 保存标准化器\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(complete_df.drop(columns=['result', 'race_id', *categorical_cols]))\n",
    "\n",
    "# 定义特征和目标变量\n",
    "X = np.hstack([scaled_features, encoded_cats])\n",
    "y = complete_df['result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc4a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按比赛分组\n",
    "grouped = complete_df.groupby('race_id')\n",
    "grouped_X = [torch.tensor(X[complete_df['race_id'] == race_id], dtype=torch.float32) for race_id in all_race_ids]\n",
    "grouped_y = [torch.tensor(y[complete_df['race_id'] == race_id], dtype=torch.float32) for race_id in all_race_ids]\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(torch.stack(grouped_X), torch.stack(grouped_y))\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)  # 每次处理一个比赛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d620e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络模型\n",
    "class HorseRankNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(HorseRankNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "input_size = X.shape[1]\n",
    "model = HorseRankNet(input_size)\n",
    "\n",
    "# 定义自定义损失函数和优化器\n",
    "class RankLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RankLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean(torch.abs(y_pred - y_true))\n",
    "    \n",
    "criterion = RankLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28bf4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逆编译函数\n",
    "def inverse_transform(X_batch, scaler, encoder):\n",
    "    num_features = scaler.mean_.shape[0]\n",
    "    categorical_features = encoder.categories_\n",
    "    \n",
    "    # 逆标准化数值特征\n",
    "    X_num = scaler.inverse_transform(X_batch[:, :num_features])\n",
    "    \n",
    "    # 逆编码类别特征\n",
    "    X_cat = encoder.inverse_transform(X_batch[:, num_features:])\n",
    "    \n",
    "    return np.hstack([X_num, X_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc8528e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.7783\n",
      "Epoch [2/50], Loss: 2.7361\n",
      "Epoch [3/50], Loss: 2.7261\n",
      "Epoch [4/50], Loss: 2.7186\n",
      "Epoch [5/50], Loss: 2.7121\n",
      "Epoch [6/50], Loss: 2.7069\n",
      "Epoch [7/50], Loss: 2.7028\n",
      "Epoch [8/50], Loss: 2.6973\n",
      "Epoch [9/50], Loss: 2.6931\n",
      "Epoch [10/50], Loss: 2.6887\n",
      "Epoch [11/50], Loss: 2.6834\n",
      "Epoch [12/50], Loss: 2.6802\n",
      "Epoch [13/50], Loss: 2.6772\n",
      "Epoch [14/50], Loss: 2.6725\n",
      "Epoch [15/50], Loss: 2.6686\n",
      "Epoch [16/50], Loss: 2.6655\n",
      "Epoch [17/50], Loss: 2.6618\n",
      "Epoch [18/50], Loss: 2.6580\n",
      "Epoch [19/50], Loss: 2.6543\n",
      "Epoch [20/50], Loss: 2.6515\n",
      "Epoch [21/50], Loss: 2.6485\n",
      "Epoch [22/50], Loss: 2.6467\n",
      "Epoch [23/50], Loss: 2.6406\n",
      "Epoch [24/50], Loss: 2.6366\n",
      "Epoch [25/50], Loss: 2.6321\n",
      "Epoch [26/50], Loss: 2.6294\n",
      "Epoch [27/50], Loss: 2.6251\n",
      "Epoch [28/50], Loss: 2.6211\n",
      "Epoch [29/50], Loss: 2.6172\n",
      "Epoch [30/50], Loss: 2.6146\n",
      "Epoch [31/50], Loss: 2.6084\n",
      "Epoch [32/50], Loss: 2.6063\n",
      "Epoch [33/50], Loss: 2.5988\n",
      "Epoch [34/50], Loss: 2.5966\n",
      "Epoch [35/50], Loss: 2.5931\n",
      "Epoch [36/50], Loss: 2.5881\n",
      "Epoch [37/50], Loss: 2.5825\n",
      "Epoch [38/50], Loss: 2.5780\n",
      "Epoch [39/50], Loss: 2.5738\n",
      "Epoch [40/50], Loss: 2.5688\n",
      "Epoch [41/50], Loss: 2.5650\n",
      "Epoch [42/50], Loss: 2.5601\n",
      "Epoch [43/50], Loss: 2.5568\n",
      "Epoch [44/50], Loss: 2.5508\n",
      "Epoch [45/50], Loss: 2.5468\n",
      "Epoch [46/50], Loss: 2.5414\n",
      "Epoch [47/50], Loss: 2.5369\n",
      "Epoch [48/50], Loss: 2.5319\n",
      "Epoch [49/50], Loss: 2.5252\n",
      "Epoch [50/50], Loss: 2.5232\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch.squeeze(0))\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 打印每个 epoch 的损失\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c350419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Absolute Error: 2.4915\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        outputs = model(X_batch.squeeze(0))\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        total_loss += loss.item()\n",
    "    print(f'Test Mean Absolute Error: {total_loss / len(train_loader):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
