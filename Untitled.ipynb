{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8616b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b9c5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "df_races = pd.read_csv('races.csv')\n",
    "df_runs = pd.read_csv('runs.csv')\n",
    "\n",
    "# 合并数据集\n",
    "df_combined = pd.merge(df_runs, df_races, on='race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1bf3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填补缺失值\n",
    "df_races.fillna(df_races.mean(), inplace=True)\n",
    "df_runs.fillna(df_runs.mean(), inplace=True)\n",
    "\n",
    "# 转换日期格式\n",
    "df_races['date'] = pd.to_datetime(df_races['date'])\n",
    "\n",
    "# 增加骑师的总比赛场次和胜利场次列\n",
    "df_runs['total_races'] = df_runs.groupby('jockey_id').cumcount() + 1\n",
    "df_runs['total_wins'] = df_runs.groupby('jockey_id')['won'].cumsum()\n",
    "\n",
    "# 合并数据集\n",
    "df_combined = pd.merge(df_runs, df_races, on='race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a22fc65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (79447, 52)\n"
     ]
    }
   ],
   "source": [
    "# 定义要使用的特征和标签\n",
    "features = ['venue', 'config', 'surface', 'distance', 'horse_age', 'horse_country', 'horse_type', \n",
    "            'horse_rating', 'declared_weight', 'actual_weight', 'total_races', 'total_wins']\n",
    "label = 'result'\n",
    "\n",
    "# 确定需要进行one-hot编码的类别特征\n",
    "categorical_features = ['venue', 'config', 'surface', 'distance', 'horse_country', 'horse_type']\n",
    "\n",
    "# 创建预处理管道\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # 其余特征保持原样\n",
    ")\n",
    "\n",
    "# 先拟合预处理器\n",
    "preprocessor.fit(df_combined[features])\n",
    "\n",
    "# 确保所有特征都被正确编码\n",
    "X = preprocessor.transform(df_combined[features])\n",
    "print(\"Shape of X:\", X.shape)\n",
    "\n",
    "# 将稀疏矩阵转换为密集矩阵\n",
    "X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# 创建一个DataFrame来存储预处理后的数据\n",
    "df_processed = pd.DataFrame(X_dense, columns=preprocessor.get_feature_names_out())\n",
    "df_processed['race_id'] = df_combined['race_id'].values\n",
    "df_processed['label'] = df_combined[label].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c2c7610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_padded: (88872, 54)\n",
      "First few rows of X_padded:\n",
      "[[0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e+00 6.000e+01 1.020e+03\n",
      "  1.330e+02 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e+00 6.000e+01 9.800e+02\n",
      "  1.330e+02 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e+00 6.000e+01 1.082e+03\n",
      "  1.320e+02 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e+00 6.000e+01 1.118e+03\n",
      "  1.270e+02 1.000e+00 0.000e+00]\n",
      " [0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 3.000e+00 6.000e+01 9.720e+02\n",
      "  1.310e+02 1.000e+00 0.000e+00]]\n",
      "Shape of X_padded: (88872, 52)\n",
      "First few rows of y_padded:\n",
      "[10  8  7  9  6]\n",
      "Shape of y_padded: (88872,)\n",
      "Shape of y_padded_repeated: (88872,)\n"
     ]
    }
   ],
   "source": [
    "# 确定每场比赛中最大的马匹数量\n",
    "max_horses_per_race = 14\n",
    "\n",
    "# 定义填充函数\n",
    "def pad_race_data(group, max_horses):\n",
    "    current_length = len(group)\n",
    "    if current_length < max_horses:\n",
    "        padding_length = max_horses - current_length\n",
    "        pad_features = np.zeros((padding_length, group.shape[1] - 2))  # 减去 race_id 和 label\n",
    "        pad_df_features = pd.DataFrame(pad_features, columns=group.columns[:-2])\n",
    "        pad_race_ids = pd.DataFrame({'race_id': [group['race_id'].iloc[0]] * padding_length})\n",
    "        pad_labels = pd.DataFrame({'label': [0] * padding_length})\n",
    "        pad_df = pd.concat([pad_df_features, pad_race_ids, pad_labels], axis=1)\n",
    "        group = pd.concat([group, pad_df], ignore_index=True)\n",
    "    return group\n",
    "\n",
    "# 对每场比赛的数据进行填充\n",
    "df_padded = df_processed.groupby('race_id').apply(pad_race_data, max_horses=max_horses_per_race).reset_index(drop=True)\n",
    "\n",
    "# 验证填充后的形状\n",
    "print(\"Shape of df_padded:\", df_padded.shape)\n",
    "\n",
    "# 重新分离特征和标签\n",
    "X_padded = df_padded.drop(columns=['race_id', 'label']).values\n",
    "y_padded = df_padded['label'].values\n",
    "\n",
    "# 打印填充后的 X 和 y\n",
    "print(\"First few rows of X_padded:\")\n",
    "print(X_padded[:5])\n",
    "print(\"Shape of X_padded:\", X_padded.shape)\n",
    "\n",
    "print(\"First few rows of y_padded:\")\n",
    "print(y_padded[:5])\n",
    "print(\"Shape of y_padded:\", y_padded.shape)\n",
    "\n",
    "# 将 y_padded 重构为与 X_padded 形状匹配的标签数组\n",
    "y_padded_repeated = np.repeat(y_padded, 1)  # 保持 y_padded 的形状与 X_padded 一致\n",
    "\n",
    "# 确保 `y_padded_repeated` 的形状与 `X_padded` 一致\n",
    "print(\"Shape of y_padded_repeated:\", y_padded_repeated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26bb2eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3697044 into shape (14,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m num_features \u001b[38;5;241m=\u001b[39m X_padded\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 重塑X_train和X_test的形状以适应LSTM\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_horses_per_race\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_horses_per_race\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, max_horses_per_race, num_features \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m max_horses_per_race)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3697044 into shape (14,3)"
     ]
    }
   ],
   "source": [
    "# 将数据拆分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_padded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 计算每个样本的特征数量\n",
    "num_features = X_padded.shape[1]\n",
    "\n",
    "# 重塑X_train和X_test的形状以适应LSTM\n",
    "X_train = X_train.reshape(-1, max_horses_per_race, num_features // max_horses_per_race)\n",
    "X_test = X_test.reshape(-1, max_horses_per_race, num_features // max_horses_per_race)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测与评估\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# 计算准确率和F1分数\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy = accuracy_score(y_test.flatten(), y_pred.flatten())\n",
    "f1 = f1_score(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41301527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 绘制训练过程中的准确率和损失曲线\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 混淆矩阵\n",
    "conf_matrix = confusion_matrix(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76b2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('horse_racing_prediction_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d75957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
